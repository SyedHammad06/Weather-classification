{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":2854929,"sourceType":"datasetVersion","datasetId":1715246}],"dockerImageVersionId":30588,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Import needed modules","metadata":{}},{"cell_type":"code","source":"!pip install tensorflow==2.9.1","metadata":{"execution":{"iopub.status.busy":"2024-10-21T05:02:07.977082Z","iopub.execute_input":"2024-10-21T05:02:07.978081Z"},"trusted":true},"execution_count":null,"outputs":[{"name":"stdout","text":"Collecting tensorflow==2.9.1\n  Obtaining dependency information for tensorflow==2.9.1 from https://files.pythonhosted.org/packages/0b/3f/57bb9bbd2dfecba3659aedffb54bb837e83ccba81f217cb744f26d453048/tensorflow-2.9.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata\n  Downloading tensorflow-2.9.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.0 kB)\nRequirement already satisfied: absl-py>=1.0.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow==2.9.1) (1.4.0)\nRequirement already satisfied: astunparse>=1.6.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow==2.9.1) (1.6.3)\nCollecting flatbuffers<2,>=1.12 (from tensorflow==2.9.1)\n  Obtaining dependency information for flatbuffers<2,>=1.12 from https://files.pythonhosted.org/packages/eb/26/712e578c5f14e26ae3314c39a1bdc4eb2ec2f4ddc89b708cf8e0a0d20423/flatbuffers-1.12-py2.py3-none-any.whl.metadata\n  Downloading flatbuffers-1.12-py2.py3-none-any.whl.metadata (872 bytes)\nRequirement already satisfied: gast<=0.4.0,>=0.2.1 in /opt/conda/lib/python3.10/site-packages (from tensorflow==2.9.1) (0.4.0)\nRequirement already satisfied: google-pasta>=0.1.1 in /opt/conda/lib/python3.10/site-packages (from tensorflow==2.9.1) (0.2.0)\nRequirement already satisfied: grpcio<2.0,>=1.24.3 in /opt/conda/lib/python3.10/site-packages (from tensorflow==2.9.1) (1.51.1)\nRequirement already satisfied: h5py>=2.9.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow==2.9.1) (3.9.0)\nCollecting keras<2.10.0,>=2.9.0rc0 (from tensorflow==2.9.1)\n  Obtaining dependency information for keras<2.10.0,>=2.9.0rc0 from https://files.pythonhosted.org/packages/ff/ff/f25909606aed26981a8bd6d263f89d64a20ca5e5316e6aafb4c75d9ec8ae/keras-2.9.0-py2.py3-none-any.whl.metadata\n  Downloading keras-2.9.0-py2.py3-none-any.whl.metadata (1.3 kB)\nCollecting keras-preprocessing>=1.1.1 (from tensorflow==2.9.1)\n  Obtaining dependency information for keras-preprocessing>=1.1.1 from https://files.pythonhosted.org/packages/79/4c/7c3275a01e12ef9368a892926ab932b33bb13d55794881e3573482b378a7/Keras_Preprocessing-1.1.2-py2.py3-none-any.whl.metadata\n  Downloading Keras_Preprocessing-1.1.2-py2.py3-none-any.whl.metadata (1.9 kB)\nRequirement already satisfied: libclang>=13.0.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow==2.9.1) (16.0.6)\nRequirement already satisfied: numpy>=1.20 in /opt/conda/lib/python3.10/site-packages (from tensorflow==2.9.1) (1.24.3)\nRequirement already satisfied: opt-einsum>=2.3.2 in /opt/conda/lib/python3.10/site-packages (from tensorflow==2.9.1) (3.3.0)\nRequirement already satisfied: packaging in /opt/conda/lib/python3.10/site-packages (from tensorflow==2.9.1) (21.3)\nCollecting protobuf<3.20,>=3.9.2 (from tensorflow==2.9.1)\n  Obtaining dependency information for protobuf<3.20,>=3.9.2 from https://files.pythonhosted.org/packages/26/ef/bd6ba3b4ff9a35944bdd325e2c9ee56f71e855757f7d43938232499f0278/protobuf-3.19.6-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata\n  Downloading protobuf-3.19.6-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (787 bytes)\nRequirement already satisfied: setuptools in /opt/conda/lib/python3.10/site-packages (from tensorflow==2.9.1) (68.1.2)\nRequirement already satisfied: six>=1.12.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow==2.9.1) (1.16.0)\nCollecting tensorboard<2.10,>=2.9 (from tensorflow==2.9.1)\n  Obtaining dependency information for tensorboard<2.10,>=2.9 from https://files.pythonhosted.org/packages/ee/0d/23812e6ce63b3d87c39bc9fee83e28c499052fa83fddddd7daea21a6d620/tensorboard-2.9.1-py3-none-any.whl.metadata\n  Downloading tensorboard-2.9.1-py3-none-any.whl.metadata (1.9 kB)\nRequirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /opt/conda/lib/python3.10/site-packages (from tensorflow==2.9.1) (0.34.0)\nCollecting tensorflow-estimator<2.10.0,>=2.9.0rc0 (from tensorflow==2.9.1)\n  Obtaining dependency information for tensorflow-estimator<2.10.0,>=2.9.0rc0 from https://files.pythonhosted.org/packages/61/e1/a72ec68403d91ba433018db58859fd4706642aa9d0fb44ff778934fc4c2c/tensorflow_estimator-2.9.0-py2.py3-none-any.whl.metadata\n  Downloading tensorflow_estimator-2.9.0-py2.py3-none-any.whl.metadata (1.3 kB)\nRequirement already satisfied: termcolor>=1.1.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow==2.9.1) (2.3.0)\nRequirement already satisfied: typing-extensions>=3.6.6 in /opt/conda/lib/python3.10/site-packages (from tensorflow==2.9.1) (4.5.0)\nRequirement already satisfied: wrapt>=1.11.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow==2.9.1) (1.15.0)\nRequirement already satisfied: wheel<1.0,>=0.23.0 in /opt/conda/lib/python3.10/site-packages (from astunparse>=1.6.0->tensorflow==2.9.1) (0.41.2)\nRequirement already satisfied: google-auth<3,>=1.6.3 in /opt/conda/lib/python3.10/site-packages (from tensorboard<2.10,>=2.9->tensorflow==2.9.1) (2.22.0)\nCollecting google-auth-oauthlib<0.5,>=0.4.1 (from tensorboard<2.10,>=2.9->tensorflow==2.9.1)\n  Obtaining dependency information for google-auth-oauthlib<0.5,>=0.4.1 from https://files.pythonhosted.org/packages/b1/0e/0636cc1448a7abc444fb1b3a63655e294e0d2d49092dc3de05241be6d43c/google_auth_oauthlib-0.4.6-py2.py3-none-any.whl.metadata\n  Downloading google_auth_oauthlib-0.4.6-py2.py3-none-any.whl.metadata (2.7 kB)\nRequirement already satisfied: markdown>=2.6.8 in /opt/conda/lib/python3.10/site-packages (from tensorboard<2.10,>=2.9->tensorflow==2.9.1) (3.4.4)\nRequirement already satisfied: requests<3,>=2.21.0 in /opt/conda/lib/python3.10/site-packages (from tensorboard<2.10,>=2.9->tensorflow==2.9.1) (2.31.0)\nCollecting tensorboard-data-server<0.7.0,>=0.6.0 (from tensorboard<2.10,>=2.9->tensorflow==2.9.1)\n  Obtaining dependency information for tensorboard-data-server<0.7.0,>=0.6.0 from https://files.pythonhosted.org/packages/60/f9/802efd84988bffd9f644c03b6e66fde8e76c3aa33db4279ddd11c5d61f4b/tensorboard_data_server-0.6.1-py3-none-manylinux2010_x86_64.whl.metadata\n  Downloading tensorboard_data_server-0.6.1-py3-none-manylinux2010_x86_64.whl.metadata (1.1 kB)\nCollecting tensorboard-plugin-wit>=1.6.0 (from tensorboard<2.10,>=2.9->tensorflow==2.9.1)\n  Obtaining dependency information for tensorboard-plugin-wit>=1.6.0 from https://files.pythonhosted.org/packages/e0/68/e8ecfac5dd594b676c23a7f07ea34c197d7d69b3313afdf8ac1b0a9905a2/tensorboard_plugin_wit-1.8.1-py3-none-any.whl.metadata\n  Downloading tensorboard_plugin_wit-1.8.1-py3-none-any.whl.metadata (873 bytes)\nRequirement already satisfied: werkzeug>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from tensorboard<2.10,>=2.9->tensorflow==2.9.1) (3.0.1)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging->tensorflow==2.9.1) (3.0.9)\nRequirement already satisfied: cachetools<6.0,>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow==2.9.1) (4.2.4)\nRequirement already satisfied: pyasn1-modules>=0.2.1 in /opt/conda/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow==2.9.1) (0.2.7)\nRequirement already satisfied: rsa<5,>=3.1.4 in /opt/conda/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow==2.9.1) (4.9)\nRequirement already satisfied: urllib3<2.0 in /opt/conda/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow==2.9.1) (1.26.15)\nRequirement already satisfied: requests-oauthlib>=0.7.0 in /opt/conda/lib/python3.10/site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.10,>=2.9->tensorflow==2.9.1) (1.3.1)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorboard<2.10,>=2.9->tensorflow==2.9.1) (3.2.0)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorboard<2.10,>=2.9->tensorflow==2.9.1) (3.4)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorboard<2.10,>=2.9->tensorflow==2.9.1) (2023.7.22)\nRequirement already satisfied: MarkupSafe>=2.1.1 in /opt/conda/lib/python3.10/site-packages (from werkzeug>=1.0.1->tensorboard<2.10,>=2.9->tensorflow==2.9.1) (2.1.3)\nRequirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /opt/conda/lib/python3.10/site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow==2.9.1) (0.4.8)\nRequirement already satisfied: oauthlib>=3.0.0 in /opt/conda/lib/python3.10/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.10,>=2.9->tensorflow==2.9.1) (3.2.2)\nDownloading tensorflow-2.9.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (511.7 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m511.7/511.7 MB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading flatbuffers-1.12-py2.py3-none-any.whl (15 kB)\nDownloading keras-2.9.0-py2.py3-none-any.whl (1.6 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m62.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading Keras_Preprocessing-1.1.2-py2.py3-none-any.whl (42 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.6/42.6 kB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading protobuf-3.19.6-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.1 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m54.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading tensorboard-2.9.1-py3-none-any.whl (5.8 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.8/5.8 MB\u001b[0m \u001b[31m87.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n\u001b[?25hDownloading tensorflow_estimator-2.9.0-py2.py3-none-any.whl (438 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m438.7/438.7 kB\u001b[0m \u001b[31m36.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading google_auth_oauthlib-0.4.6-py2.py3-none-any.whl (18 kB)\nDownloading tensorboard_data_server-0.6.1-py3-none-manylinux2010_x86_64.whl (4.9 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.9/4.9 MB\u001b[0m \u001b[31m65.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading tensorboard_plugin_wit-1.8.1-py3-none-any.whl (781 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m781.3/781.3 kB\u001b[0m \u001b[31m51.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hInstalling collected packages: tensorboard-plugin-wit, keras, flatbuffers, tensorflow-estimator, tensorboard-data-server, protobuf, keras-preprocessing, google-auth-oauthlib, tensorboard, tensorflow\n  Attempting uninstall: keras\n    Found existing installation: keras 2.13.1\n    Uninstalling keras-2.13.1:\n      Successfully uninstalled keras-2.13.1\n  Attempting uninstall: flatbuffers\n    Found existing installation: flatbuffers 23.5.26\n    Uninstalling flatbuffers-23.5.26:\n      Successfully uninstalled flatbuffers-23.5.26\n  Attempting uninstall: tensorflow-estimator\n    Found existing installation: tensorflow-estimator 2.13.0\n    Uninstalling tensorflow-estimator-2.13.0:\n      Successfully uninstalled tensorflow-estimator-2.13.0\n  Attempting uninstall: tensorboard-data-server\n    Found existing installation: tensorboard-data-server 0.7.1\n    Uninstalling tensorboard-data-server-0.7.1:\n      Successfully uninstalled tensorboard-data-server-0.7.1\n  Attempting uninstall: protobuf\n    Found existing installation: protobuf 3.20.3\n    Uninstalling protobuf-3.20.3:\n      Successfully uninstalled protobuf-3.20.3\n  Attempting uninstall: google-auth-oauthlib\n    Found existing installation: google-auth-oauthlib 1.0.0\n    Uninstalling google-auth-oauthlib-1.0.0:\n      Successfully uninstalled google-auth-oauthlib-1.0.0\n  Attempting uninstall: tensorboard\n    Found existing installation: tensorboard 2.13.0\n    Uninstalling tensorboard-2.13.0:\n      Successfully uninstalled tensorboard-2.13.0\n  Attempting uninstall: tensorflow\n    Found existing installation: tensorflow 2.13.0\n    Uninstalling tensorflow-2.13.0:\n","output_type":"stream"}]},{"cell_type":"code","source":"# import system libs\nimport os\nimport time\nimport shutil\nimport pathlib\nimport itertools\nfrom PIL import Image\n# import data handling tools\nimport cv2\nimport numpy as np\nimport pandas as pd\nimport seaborn as sns\nsns.set_style('darkgrid')\nimport matplotlib.pyplot as plt\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import confusion_matrix, classification_report\n# import Deep learning Libraries\nimport tensorflow as tf\nfrom tensorflow import keras\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.optimizers import Adam, Adamax\nfrom tensorflow.keras.metrics import categorical_crossentropy\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Activation, Dropout, BatchNormalization\nfrom tensorflow.keras import regularizers\n\n# Ignore Warnings\nimport warnings\nwarnings.filterwarnings(\"ignore\")\n\nprint ('modules loaded')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import os \nos.listdir(/kaggle/input/weather-dataset/dataset)","metadata":{"execution":{"iopub.status.busy":"2024-10-21T05:27:37.083437Z","iopub.status.idle":"2024-10-21T05:27:37.083827Z","shell.execute_reply.started":"2024-10-21T05:27:37.083611Z","shell.execute_reply":"2024-10-21T05:27:37.083634Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Data Preprocessing","metadata":{}},{"cell_type":"markdown","source":"**Read data and store it in dataframe**","metadata":{}},{"cell_type":"code","source":"# Generate data paths with labels\ndata_dir = '/kaggle/input/weather-dataset/dataset'\nfilepaths = []\nlabels = []\n\nfolds = os.listdir(data_dir)\nfor fold in folds:\n    foldpath = os.path.join(data_dir, fold)\n    filelist = os.listdir(foldpath)\n    for file in filelist:\n        fpath = os.path.join(foldpath, file)\n        filepaths.append(fpath)\n        labels.append(fold)\n\n# Concatenate data paths with labels into one dataframe\nFseries = pd.Series(filepaths, name= 'filepaths')\nLseries = pd.Series(labels, name='labels')\ndf = pd.concat([Fseries, Lseries], axis= 1)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Split dataframe into train, valid, and test**","metadata":{}},{"cell_type":"code","source":"# train dataframe\ntrain_df, dummy_df = train_test_split(df,  train_size= 0.8, shuffle= True, random_state= 123)\n\n# valid and test dataframe\nvalid_df, test_df = train_test_split(dummy_df,  train_size= 0.6, shuffle= True, random_state= 123)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import os\nclass_names = os.listdir(\"/kaggle/input/weather-dataset/dataset/\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Create image data generator**","metadata":{}},{"cell_type":"code","source":"# crobed image size\nbatch_size = 64\nimg_size = (224, 224)\nchannels = 3\nimg_shape = (img_size[0], img_size[1], channels)\n\n# Recommended : use custom function for test data batch size, else we can use normal batch size.\nts_length = len(test_df)\ntest_batch_size = max(sorted([ts_length // n for n in range(1, ts_length + 1) if ts_length%n == 0 and ts_length/n <= 80]))\ntest_steps = ts_length // test_batch_size\n\n# This function which will be used in image data generator for data augmentation, it just take the image and return it again.\ndef scalar(img):\n    return img\n\ntr_gen = ImageDataGenerator(preprocessing_function= scalar)\nts_gen = ImageDataGenerator(preprocessing_function= scalar)\ntrain_gen = tr_gen.flow_from_dataframe( train_df, x_col= 'filepaths', y_col= 'labels', target_size= img_size, class_mode= 'categorical',\n                                    color_mode= 'rgb', shuffle= True, batch_size= batch_size)\n\nvalid_gen = ts_gen.flow_from_dataframe( valid_df, x_col= 'filepaths', y_col= 'labels', target_size= img_size, class_mode= 'categorical',\n                                    color_mode= 'rgb', shuffle= True, batch_size= batch_size)\n\n# Note: we will use custom test_batch_size, and make shuffle= false\ntest_gen = ts_gen.flow_from_dataframe( test_df, x_col= 'filepaths', y_col= 'labels', target_size= img_size, class_mode= 'categorical',\n                                    color_mode= 'rgb', shuffle= False, batch_size= test_batch_size)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Show sample from train data**","metadata":{}},{"cell_type":"code","source":"g_dict = train_gen.class_indices      # defines dictionary {'class': index}\nclasses = list(g_dict.keys())       # defines list of dictionary's kays (classes), classes names : string\nimages, labels = next(train_gen)      # get a batch size samples from the generator\n\n# calculate number of displayed samples\nlength = len(labels)        # length of batch size\nsample = min(length, 25)    # check if sample less than 25 images\n\nplt.figure(figsize= (20, 20))\nfor i in range(sample):\n    plt.subplot(5, 5, i + 1)\n    image = images[i] / 255       # scales data to range (0 - 255)\n    plt.imshow(image)\n    index = np.argmax(labels[i])  # get image index\n    class_name = classes[index]   # get class of image\n    plt.title(class_name, color= 'blue', fontsize= 12)\n    plt.axis('off')\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Model Structure","metadata":{}},{"cell_type":"markdown","source":"**Generic Model Creation**","metadata":{}},{"cell_type":"code","source":"# Create Model Structure\nimg_size = (224, 224)\nchannels = 3\nimg_shape = (img_size[0], img_size[1], channels)\nclass_count = len(list(train_gen.class_indices.keys())) # to define number of classes in dense layer\n\n# create pre-trained model (you can built on pretrained model such as :  efficientnet, VGG , Resnet )\n# we will use efficientnetb3 from EfficientNet family.\nbase_model = tf.keras.applications.efficientnet.EfficientNetB3(include_top= False, weights= \"imagenet\", input_shape= img_shape, pooling= 'max')\n\nmodel = Sequential([\n    base_model,\n    BatchNormalization(axis= -1, momentum= 0.99, epsilon= 0.001),\n    Dense(256, kernel_regularizer= regularizers.l2(l= 0.016), activity_regularizer= regularizers.l1(0.006),\n                bias_regularizer= regularizers.l1(0.006), activation= 'relu'),\n    Dropout(rate= 0.45, seed= 123),\n    Dense(class_count, activation= 'softmax')\n])\n\nmodel.compile(Adamax(learning_rate= 0.001), loss= 'categorical_crossentropy', metrics= ['accuracy'])\n\nmodel.summary()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Train model","metadata":{}},{"cell_type":"code","source":"epochs = 20   # number of all epochs in training\n\nhistory = model.fit(x= train_gen, epochs= epochs, verbose= 1, validation_data= valid_gen, \n                    validation_steps= None, shuffle= False)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Display model performance**","metadata":{}},{"cell_type":"code","source":"# Define needed variables\ntr_acc = history.history['accuracy']\ntr_loss = history.history['loss']\nval_acc = history.history['val_accuracy']\nval_loss = history.history['val_loss']\nindex_loss = np.argmin(val_loss)\nval_lowest = val_loss[index_loss]\nindex_acc = np.argmax(val_acc)\nacc_highest = val_acc[index_acc]\nEpochs = [i+1 for i in range(len(tr_acc))]\nloss_label = f'best epoch= {str(index_loss + 1)}'\nacc_label = f'best epoch= {str(index_acc + 1)}'\n# Plot training history\nplt.figure(figsize= (20, 8))\nplt.style.use('fivethirtyeight')\nplt.subplot(1, 2, 1)\nplt.plot(Epochs, tr_loss, 'r', label= 'Training loss')\nplt.plot(Epochs, val_loss, 'g', label= 'Validation loss')\nplt.scatter(index_loss + 1, val_lowest, s= 150, c= 'blue', label= loss_label)\nplt.title('Training and Validation Loss')\nplt.xlabel('Epochs')\nplt.ylabel('Loss')\nplt.legend()\nplt.subplot(1, 2, 2)\nplt.plot(Epochs, tr_acc, 'r', label= 'Training Accuracy')\nplt.plot(Epochs, val_acc, 'g', label= 'Validation Accuracy')\nplt.scatter(index_acc + 1 , acc_highest, s= 150, c= 'blue', label= acc_label)\nplt.title('Training and Validation Accuracy')\nplt.xlabel('Epochs')\nplt.ylabel('Accuracy')\nplt.legend()\n\nplt.tight_layout\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Evaluate model","metadata":{}},{"cell_type":"code","source":"ts_length = len(test_df)\ntest_batch_size = max(sorted([ts_length // n for n in range(1, ts_length + 1) if ts_length%n == 0 and ts_length/n <= 80]))\ntest_steps = ts_length // test_batch_size\n\ntrain_score = model.evaluate(train_gen, steps= test_steps, verbose= 1)\nvalid_score = model.evaluate(valid_gen, steps= test_steps, verbose= 1)\ntest_score = model.evaluate(test_gen, steps= test_steps, verbose= 1)\nprint(\"Train Loss: \", train_score[0])\nprint(\"Train Accuracy: \", train_score[1])\nprint('-' * 20)\nprint(\"Validation Loss: \", valid_score[0])\nprint(\"Validation Accuracy: \", valid_score[1])\nprint('-' * 20)\nprint(\"Test Loss: \", test_score[0])\nprint(\"Test Accuracy: \", test_score[1])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Get Predictions**","metadata":{}},{"cell_type":"code","source":"preds = model.predict_generator(test_gen)\ny_pred = np.argmax(preds, axis=1)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Confusion Matrics and Classification Report**","metadata":{}},{"cell_type":"code","source":"g_dict = test_gen.class_indices\nclasses = list(g_dict.keys())\n\n# Confusion matrix\ncm = confusion_matrix(test_gen.classes, y_pred)\n\nplt.figure(figsize= (10, 10))\nplt.imshow(cm, interpolation= 'nearest', cmap= plt.cm.Blues)\nplt.title('Confusion Matrix')\nplt.colorbar()\ntick_marks = np.arange(len(classes))\nplt.xticks(tick_marks, classes, rotation= 45)\nplt.yticks(tick_marks, classes)\nthresh = cm.max() / 2.\nfor i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n    plt.text(j, i, cm[i, j], horizontalalignment= 'center', color= 'white' if cm[i, j] > thresh else 'black')\n\nplt.tight_layout()\nplt.ylabel('True Label')\nplt.xlabel('Predicted Label')\n\nplt.show()\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Classification report\nprint(classification_report(test_gen.classes, y_pred, target_names= classes))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Prediction using loaded_model","metadata":{}},{"cell_type":"code","source":"loaded_model = tf.keras.models.load_model('/kaggle/working/Malaria Cells.h5', compile=False)\nloaded_model.compile(Adamax(learning_rate= 0.001), loss= 'categorical_crossentropy', metrics= ['accuracy'])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"image_path = '/kaggle/input/weather-dataset/dataset/rain/1021.jpg'\nimage = Image.open(image_path)\n\n# Preprocess the image\nimg = image.resize((224, 224))\nimg_array = tf.keras.preprocessing.image.img_to_array(img)\nimg_array = tf.expand_dims(img_array, 0)\n\n# Make predictions\npredictions = loaded_model.predict(img_array)\nclass_labels = classes\nscore = tf.nn.softmax(predictions[0])\nprint(f\"{class_labels[tf.argmax(score)]}\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Specify the directory where the model will be saved\nmodel_save_path = \"/kaggle/working/\"\n\n# Save the entire model (architecture, weights, and optimizer state)\nmodel.save('weather_model.h5')\n\nprint(f\"Model saved to {model_save_path}\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}